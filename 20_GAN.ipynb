{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b9c95e7",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "\n",
    "# Tutorial 20: Generative Adversarial Network (GAN) \n",
    "\n",
    "In this tutorial, we will cover:\n",
    "\n",
    "- Creating images with a GAN\n",
    "\n",
    "Prerequisites:\n",
    "\n",
    "- Python, PyTorch, Deep Learning Training, Stochastic Gradient Descent\n",
    "\n",
    "My contact:\n",
    "\n",
    "- Niklas Beuter (niklas.beuter@th-luebeck.de)\n",
    "\n",
    "Course:\n",
    "\n",
    "- Slides and notebooks will be available at https://lernraum.th-luebeck.de/course/view.php?id=5383\n",
    "\n",
    "## Expected Outcomes\n",
    "* Understand the architecture of a GAN including a generator and a discriminator\n",
    "* Understand the difficulties of training a GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd54fa88-287a-4b90-a8fb-af16eef699f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9699762f-df88-4caa-bf0d-adbccf03e1e9",
   "metadata": {},
   "source": [
    "## Download the pokemon dataset from https://pokemondb.net/sprites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15fa0db-226d-41b1-bbc0-e5736758ce5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Erstelle ein Verzeichnis für die Bilder\n",
    "os.makedirs('data/pokemon_images', exist_ok=True)\n",
    "\n",
    "# URL der Seite mit den Pokémon-Sprites\n",
    "url = 'https://pokemondb.net/sprites'\n",
    "\n",
    "# Lade die Seite herunter\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Finde alle Bild-Links auf der Seite\n",
    "img_tags = soup.find_all('img')\n",
    "img_urls = [img['src'] for img in img_tags if 'src' in img.attrs and img['src'].startswith('https://img.pokemondb.net/sprites/')]\n",
    "\n",
    "# Lade die Bilder herunter\n",
    "for img_url in img_urls:\n",
    "    img_name = os.path.basename(img_url)\n",
    "    img_path = os.path.join('data/pokemon_images', img_name)\n",
    "    with open(img_path, 'wb') as f:\n",
    "        img_data = requests.get(img_url).content\n",
    "        f.write(img_data)\n",
    "\n",
    "print('Bilder wurden erfolgreich heruntergeladen.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8a29c7-2186-417c-aa1b-569dbbd59b32",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4be4a0-020f-4405-a112-d7899a65e54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Bildtransformationen\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Lade und transformiere die Bilder\n",
    "def load_images(image_folder):\n",
    "    images = []\n",
    "    for img_path in glob.glob(f'{image_folder}/*.png'):\n",
    "        img = Image.open(img_path)\n",
    "        img = img.convert('RGB')  # Stelle sicher, dass das Bild RGB ist\n",
    "        img = transform(img)\n",
    "        images.append(img)\n",
    "    return torch.stack(images)\n",
    "\n",
    "# Lade die Pokémon-Bilder\n",
    "images = load_images('data/pokemon_images')\n",
    "print(f'{len(images)} Bilder wurden erfolgreich geladen und transformiert.')\n",
    "\n",
    "# Hyperparameter\n",
    "batch_size = 32\n",
    "\n",
    "# DataLoader\n",
    "dataloader = DataLoader(images, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc35c8f9-5eeb-4b25-b77a-2816f086ab1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "# Funktion zum Anzeigen von Trainingsbildern\n",
    "def imshow(img):\n",
    "    #img = img / 2 + 0.5  # Unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# Anzeige der Trainingsbilder vor dem Training\n",
    "real_batch = next(iter(dataloader))\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "imshow(vutils.make_grid(real_batch[:64], padding=2, normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3003aab2-3d31-4a46-8ae9-44363e84be8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, nz, ngf, nc):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
    "            #nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, nc, ndf):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            #nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216a2c00-3bbe-4e3e-bb7b-005545c3be26",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063e0478-0130-4b9e-8eab-c394400a83eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "# Hyperparameter\n",
    "lr_D = 0.0002\n",
    "lr_G = 0.0005\n",
    "beta1 = 0.5\n",
    "nz = 50  # Größe des latenten Vektors\n",
    "ngf = 64\n",
    "ndf = 64\n",
    "num_epochs = 100\n",
    "\n",
    "# Initialisiere das Modell\n",
    "netG = Generator(nz, ngf, 3).to(device)\n",
    "netD = Discriminator(3, ndf).to(device)\n",
    "\n",
    "# Gewichte initialisieren\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "netG.apply(weights_init)\n",
    "netD.apply(weights_init)\n",
    "\n",
    "# Optimizer\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr_D, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr_G, betas=(beta1, 0.999))\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Training Loop\n",
    "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        # Update Discriminator\n",
    "        netD.zero_grad()\n",
    "        real_cpu = data.to(device)\n",
    "        b_size = real_cpu.size(0)\n",
    "        label = torch.full((b_size,), 0.9, dtype=torch.float, device=device)\n",
    "        output = netD(real_cpu).view(-1)\n",
    "        errD_real = criterion(output, label)\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "        fake = netG(noise)\n",
    "        label.fill_(0.1)\n",
    "        output = netD(fake.detach()).view(-1)\n",
    "        errD_fake = criterion(output, label)\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        errD = errD_real + errD_fake\n",
    "        optimizerD.step()\n",
    "\n",
    "        # Update Generator\n",
    "        netG.zero_grad()\n",
    "        label.fill_(0.9) # the generator needs the discriminator to classify the faked images as true images\n",
    "        output = netD(fake).view(-1) # classify the faked image\n",
    "        errG = criterion(output, label) # in case the classifier classifies the faked image as fake, the generator gets a high loss and hence, needs to update its parameters\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        optimizerG.step()\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            print(f'[{epoch}/{num_epochs}][{i}/{len(dataloader)}] Loss_D: {errD.item():.4f} Loss_G: {errG.item():.4f} D(x): {D_x:.4f} D(G(z)): {D_G_z1:.4f} / {D_G_z2:.4f}')\n",
    "\n",
    "    # Speichere generierte Bilder\n",
    "    if epoch % 100 == 0 or epoch == num_epochs - 1:\n",
    "        with torch.no_grad():\n",
    "            fake = netG(fixed_noise).detach().cpu()\n",
    "        vutils.save_image(fake, f'results/fake_samples_epoch_{epoch}.png', normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7356d800-e49a-4377-89b9-594b863ae245",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(netG)\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74acebd-8b61-479b-b97b-1ddccdf902d3",
   "metadata": {},
   "source": [
    "## Generate images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f638f699-96ae-4193-99dc-108008b454bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lade das trainierte Modell (falls gespeichert)\n",
    "#netG.load_state_dict(torch.load('netG.pth'))\n",
    "\n",
    "# Generiere neue Pokémon-Bilder\n",
    "noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "with torch.no_grad():\n",
    "    fake = netG(noise).detach().cpu()\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Generated Images at Epoch {epoch}\")\n",
    "    imshow(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "    plt.show()\n",
    "#vutils.save_image(fake, 'results/generated_pokemon.png', normalize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
