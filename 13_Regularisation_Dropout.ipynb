{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "\n",
    "# Tutorial 13: Regularisation Layer - Dropout\n",
    "\n",
    "In this tutorial, we will cover:\n",
    "\n",
    "- Regularisation, Dropout\n",
    "\n",
    "Prerequisites:\n",
    "\n",
    "- Python, Tensor basics, DNN Training, Overfitting\n",
    "\n",
    "My contact:\n",
    "\n",
    "- Niklas Beuter (niklas.beuter@th-luebeck.de)\n",
    "\n",
    "Course:\n",
    "\n",
    "- Slides and notebooks will be available at https://lernraum.th-luebeck.de/course/view.php?id=5383\n",
    "\n",
    "## Expected Outcomes\n",
    "* Understand regularisation: dropout layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why do we need regularisation?\n",
    "\n",
    "When a neural network model learns not only the underlying patterns in the training data but also the noise and random fluctuations, we call it overfitting. As a result, while the model performs exceptionally well on training data, its performance on new, unseen data is poor.\n",
    "\n",
    "### Causes of Overfitting\n",
    "1. **Too many parameters**: Having more parameters than necessary can lead the model to fit excessively to the training data.\n",
    "2. **Insufficient training data**: Without enough data, the model fails to generalize well, learning instead from the limited examples provided.\n",
    "3. **Extended training time**: Training a model for too many epochs can lead it to learn from the noise in the data as well as from the actual signal.\n",
    "\n",
    "### How to Prevent Overfitting\n",
    "- **Use regularization techniques** such as L2 regularization, **Dropout**, and early stopping.\n",
    "- **Increase training data**: More data can help the model learn more general patterns.\n",
    "- **Use data augmentation**: Modifying existing training samples to create new ones can help in generalizing better.\n",
    "\n",
    "### Definition of Dropout\n",
    "Dropout is a regularization technique used in neural networks to prevent overfitting. Overfitting occurs when a model learns the detailed noise in the training data to the extent that it negatively impacts the performance of the model on new data.\n",
    "\n",
    "### How Dropout Works\n",
    "During the training phase, dropout randomly deactivates a subset of neurons in the network with a certain probability $p$, typically between 0.2 and 0.5. This means that each neuron has a chance of $p$ to be temporarily \"dropped out\" and not contribute to the forward pass or the backpropagation process during that particular training step.\n",
    "\n",
    "\n",
    "![Image from: Srivastava et al, “Dropout: A simple way to prevent neural networks from overfitting”, JMLR 2014](https://pgaleone.eu/images/dropout/dropout.jpeg)\n",
    "\n",
    "#### Mathematical Representation\n",
    "The dropout process can be mathematically represented as follows:\n",
    "\n",
    "For a given layer with input vector $x$, the output $y$ after applying dropout is:\n",
    "\n",
    "$$ y = x \\odot m $$\n",
    "\n",
    "where $\\odot$ denotes element-wise multiplication, and $m$ is a mask vector where each element is independently drawn from a Bernoulli distribution with parameter $1-p$. This mask effectively \"drops out\" a fraction of its elements by setting them to zero.\n",
    "\n",
    "### Benefits of Using Dropout\n",
    "1. **Reduces Overfitting**: By deactivating neurons randomly, dropout ensures that the network does not become overly dependent on any single neuron, promoting a more generalized model.\n",
    "2. **Encourages Neuronal Redundancy**: The network learns to use all neurons effectively, as it cannot rely on the presence of particular neurons, enhancing its ability to generalize well.\n",
    "3. **Ensemble Effect**: The process of using dropout can be seen as training a large number of thin networks (each dropout iteration represents a different network). At test time, using all neurons simulates an averaging of these networks.\n",
    "\n",
    "### Application of Dropout\n",
    "Dropout is typically applied during training. At test time, all neurons are used, but their outputs are scaled down by a factor of $1-p$ to account for the larger number of active units compared to the training phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropout from Scratch\n",
    "\n",
    "def dropout_layer(X, dropout):\n",
    "    assert 0 <= dropout <= 1\n",
    "    if dropout == 1: return torch.zeros_like(X)\n",
    "    # Create a mask based on the input size and apply dropout (set to 0 and 1)\n",
    "    mask = (torch.rand(X.shape).to(X.device) > torch.tensor(dropout).to(device)).float().to(X.device)\n",
    "    # return debiased other values of the layer\n",
    "    return mask * X / (1.0 - dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.arange(16, dtype = torch.float32).reshape((2, 8))\n",
    "print('dropout_p = 0:', dropout_layer(X, 0))\n",
    "print('dropout_p = 0.5:', dropout_layer(X, 0.5))\n",
    "print('dropout_p = 1:', dropout_layer(X, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDropout(nn.Module):\n",
    "    def __init__(self, p=0.5):\n",
    "        super(CustomDropout, self).__init__()\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            return dropout_layer(x,self.p)\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNISTModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FashionMNISTModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = CustomDropout(p=0.5)\n",
    "        self.layer2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten the image\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(images)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The transform compose is used to combine several transformations. In this case, it converts the images and normalizes them\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert images to tensors\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize the images\n",
    "])\n",
    "\n",
    "# Load datasets MNIST\n",
    "#train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "#test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Load datasets FASHION MNIST\n",
    "train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create data loaders with batch size of 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Class names for the Fashion-MNIST dataset\n",
    "fashion_mnist_classes = [\n",
    "    \"T-shirt/top\",   # Class 0\n",
    "    \"Trouser\",       # Class 1\n",
    "    \"Pullover\",      # Class 2\n",
    "    \"Dress\",         # Class 3\n",
    "    \"Coat\",          # Class 4\n",
    "    \"Sandal\",        # Class 5\n",
    "    \"Shirt\",         # Class 6\n",
    "    \"Sneaker\",       # Class 7\n",
    "    \"Bag\",           # Class 8\n",
    "    \"Ankle boot\"     # Class 9\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = FashionMNISTModel(784, 256, 10)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, criterion, optimizer)\n",
    "evaluate_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Predict classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def predict_and_visualize_single_image(model, image, label):\n",
    "    image, label = image.to(device), label.to(device)  # Move image and label to the device\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        image = image.unsqueeze(0)  # Add batch dimension\n",
    "        output = model(image)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "\n",
    "    # Move the image back to CPU for visualization\n",
    "    image = image.cpu()\n",
    "\n",
    "    # Plot the image and its predicted class\n",
    "    plt.imshow(image.squeeze(), cmap='gray')\n",
    "    plt.title(f'Actual: {label} Predicted: {predicted.item()}')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch one batch from the test_loader\n",
    "test_images, test_labels = next(iter(test_loader))\n",
    "\n",
    "print(\"Number of images in batch: \", test_images.shape[0])\n",
    "\n",
    "# Select the first image and label from the batch\n",
    "image, label = test_images[50], test_labels[50]\n",
    "\n",
    "# Predict the class \n",
    "predict_and_visualize_single_image(model, image, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Dropout Layer\n",
    "\n",
    "During evaluation (i.e., when using model.eval()), the dropout layer does not alter the input data and acts as a pass-through layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNISTModelPyTorch(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FashionMNISTModelPyTorch, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.5)  # Using built-in Dropout layer\n",
    "        self.layer2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten the image\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)  # Apply dropout after activation\n",
    "        x = self.layer2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = FashionMNISTModelPyTorch(784, 256, 10)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, criterion, optimizer)\n",
    "evaluate_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "This notebook is adapted from or uses following sources:\n",
    "* https://d2l.ai/chapter_multilayer-perceptrons/dropout.html#dropout\n",
    "* https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture10.pdf\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
